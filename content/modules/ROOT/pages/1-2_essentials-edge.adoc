= Understanding the Essentials of Edge: Strengths and Challenges

When considering moving the entire AI/ML lifecycle to the edge, it's important to weigh the pros and cons derived from this action. On the positive side, bringing AI to the edge means that models are trained, deployed and managed closer to where the data is generated, which introduces several distinct advantages:

* *Data sovereignty*: Processing data at its point of origin ensures that it remains within the local environment, eliminating the need to transport it to an outside infrastructure.
* *Limited-to-no connectivity*: Because data processing doesn't rely on network connectivity, critical operations can continue functioning uninterrupted even during network outages or in disconnected environments.
* *Faster decision-making*: With no need to transmit data over the network, latency is reduced, allowing for quicker response times and near-real-time decision-making.

However, the edge environment presents challenges as well. Beyond the typical network connectivity limitations, there are other drawbacks to consider. As we move closer to the edge, the environment becomes more constrained. AI and ML processes often demand significant power and hardware resources, which can be difficult to provide in an environment with limited space and resources. Additionally, edge locations often lack extensive dedicated IT support, requiring architectures that are resilient and simple, with operations that are automated and need minimal human intervention.

== Next section:

Once we understand the limitations we encounter in edge environments and recognize the critical role of automation, let's review the architecture and design for this demo.
