= {lab_name}

== Lab overview

This project showcases how the integration of AI and edge computing can effectively address specific customer use cases and fit seamlessly into various real-world scenarios. The demo will highlight the practical application of AI in resource-constrained environments, making it essential to use lightweight topologies and platforms such as Single Node OpenShift (SNO) and Red Hat Device Edge.

During the demo, we will develop a robust solution for the automotive industry, highlighting the importance of automation, as dedicated teams are not feasible at the edge. To address this challenge, our solution incorporates key components within Red Hat OpenShift AI to support the entire AI/ML lifecycle at the edge, including model training, data science pipelines, model serving, and model monitoring.

== Lab contents

To bring this demo to life, several technologies will be used and covered during this lab. Below is a summary of the materials that will be covered:

[width="100%",cols="6,^4,7",options="header"]
|===
| Chapter | Duration | Contents

| AI & Edge Use case | 10min 
a|- Understanding our case
- Essentials of Edge
- Explore our design

| Battery Management System | 15min 
a|- Understand the vehicle infrastructure
- Deplying MinIO storage and models
- Deplying Inference servers
- Deploying the BMS app

| RHOAI configuration | 15min 
a|- RHOAI installation
- Datascience projects
- DataConnections

| Model Re-training | 15min 
a|- Workbenches
- Import Notebooks
- Training our models

| Model Serving | 10min 
a|- Stress Detection serving
- Time to Failure serving
- Querying endpoints

| Pipelines Automation | 5min 
a|- Pipeline server
- Pipelines execution
- Pipelines scheduled automation

| Model Monitoring | 5min 
a|- TrustyAI
- Bias detection
- Data drift

| BMS app performance | 15min 
a|- Test the new models
|===